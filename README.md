# CS231n: Convolutional Neural Networks for Visual Recognition       
     
## Spring 2017

The repo contains my assignments for CS231n. The course materials can be found at [here](http://cs231n.stanford.edu/). There are 3 assignments in total.
   
1. [Assignment1](http://cs231n.github.io/assignments2017/assignment1/)
The goal of assignment1 is to understand the basic Image Classification pipeline and the data-driven approach (train/predict stages), the train/val/test splits and the use of validation data for hyperparameter tuning. The implementation and application of a k-Nearest Neighbor (kNN) classifier, a Multiclass Support Vector Machine (SVM) classifier, a Softmax classifier, and a Two layer neural network classifier are also required.

- Q1: [k-Nearest Neighbor classifier](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment1/knn.ipynb)
- Q2: [Training a Support Vector Machine](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment1/svm.ipynb) 
- Q3: [Implement a Softmax classifier](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment1/softmax.ipynb)
- Q4: [Two-Layer Neural Network](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment1/two_layer_net.ipynb)
- Q5: [Higher Level Representations: Image Features](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment1/features.ipynb)


2. [Assignment2](http://cs231n.github.io/assignments2017/assignment2/)
The goal of assignment2 is to understand Neural Network and be able to implement backprogagation, implement various optimization rules, implement batch normalization and dropout for training networks.

- Q1: [Fully-connected Neural Network](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment2/FullyConnectedNets.ipynb)
- Q2: [Batch Normalization](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment2/BatchNormalization.ipynb)
- Q3: [Dropout](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment2/Dropout.ipynb)
- Q4: [Convolutional Networks](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment2/ConvolutionalNetworks.ipynb)
- Q5: [TensorFlow on CIFAR-10](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment2/TensorFlow.ipynb)


2. [Assignment3](http://cs231n.github.io/assignments2017/assignment3/)
The goal of assignment3 is to understand the architecture of recurrent neural networks (RNNs), understand and implement both Vanilla RNNs and Long-Short Term Memory (LSTM) RNNs, how to sample from an RNN language model at test-time, how to combine convolutional neural nets and recurrent nets to implement an image captioning system, how a trained convolutional network can be used to compute gradients with respect to the input image, implement and different applications of image gradients, including saliency maps, fooling images, class visualizations, understand and implement style transfer, understand how to train and implement a generative adversarial network (GAN) to produce images that look like a dataset.

- Q1: [Image Captioning with Vanilla RNNs](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment3/RNN_Captioning.ipynb) 
- Q2: [Image Captioning with LSTMs](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment3/LSTM_Captioning.ipynb) 
- Q3: [Network Visualization: Saliency maps, Class Visualization, and Fooling Images](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment3/NetworkVisualization-TensorFlow.ipynb) 
- Q4: [Style Transfer](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment3/StyleTransfer-TensorFlow.ipynb)
- Q5: [Generative Adversarial Networks](https://github.com/SarahQiong/CS231n_2017/blob/master/assignment3/GANs-TensorFlow.ipynb)
